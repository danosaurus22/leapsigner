# leapsigner
American Sign Language to Speech Translator using LeapMotion Controller

This was a graduate class project for the Embedded Systems course (EEC 284) taught by Dr. Soheil Ghiasi in the Fall 2014 quarter at the University of California, Davis. The goal was to develop an American Sign Language to speech (English) translator to help bridge the communication gap between people who are speech impaired and those who don't know ASL. This was done using the LeapMotion Controller.

Abstract:
In order to lower the communication barrier between the deaf and hard of hearing and the hearing population in the United States, an American Sign Language (ASL) to speech translator was developed using the Leap Motion technology. This technology captures gestural information using infrared LEDs and cameras and provides an API that allows 3rd party app development. A simple pattern-matching engine was developed to match the gestural information to a specific sign and translate that into text. This text was then fed into a text-to-speech synthesizer to generate the audible speech. A visualizer was developed to provide visual feedback to the signer as to what the Leap Motion device contextually sees. Several simple signs in ASL were successfully distinguished by the system and turned into speech, thereby successfully allow communication from the deaf population to the hearing population without the need for both parties to learn ASL. This system provides a base from which future works can expand and improve upon. One such aspect should be the integration of a communication channel allowing information to flow from the hearing population to the deaf population.


https://github.com/RuZman/LeapFX

